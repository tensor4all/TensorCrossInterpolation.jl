var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = TensorCrossInterpolation","category":"page"},{"location":"#TensorCrossInterpolation","page":"Home","title":"TensorCrossInterpolation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This is the documentation for TensorCrossInterpolation.","category":"page"},{"location":"","page":"Home","title":"Home","text":"With the user manual and usage examples below, users should be able to use this library as a \"black box\" in most cases. Detailed documentation of (almost) all methods can be found in the Documentation section, and Implementation contains a detailed explanation of this implementation of TCI.","category":"page"},{"location":"#Interpolating-functions","page":"Home","title":"Interpolating functions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The most convenient way to create a TCI is crossinterpolate2. For example, consider the lorentzian in 5 dimensions, i.e. f(mathbf v) = 1(1 + mathbf v^2) on a mesh mathbfv in 1 2  10^5. f can be interpolated as follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"import TensorCrossInterpolation as TCI\nf(v) = 1/(1 + v' * v)\nlocaldims = fill(10, 5)    # There are 5 tensor indices, each with values 1...10\ntolerance = 1e-8\ntci, ranks, errors = TCI.crossinterpolate2(Float64, f, localdims; tolerance=tolerance)\nprintln(tci)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note that the return type of f has to be stated explicitly; inferring it automatically is too error-prone.","category":"page"},{"location":"","page":"Home","title":"Home","text":"To evaluate the TCI approximation, simply call it the same way as the original function. For example, to evaluate it at (1 2 3 4 5)^T, use:","category":"page"},{"location":"","page":"Home","title":"Home","text":"println(\"Original function: $(f([1, 2, 3, 4, 5]))\")\nprintln(\"TCI approximation: $(tci([1, 2, 3, 4, 5]))\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"For easy integration into tensor network algorithms, the tensor train can be converted to ITensors MPS format. If you're using julia version 1.9 or later, an extension is automatically loaded if both TensorCrossInterpolation.jl and ITensors.jl are present. For older versions of julia, use the package using TCIITensorConversion.jl.","category":"page"},{"location":"#Sums-and-Integrals","page":"Home","title":"Sums and Integrals","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Tensor trains are a way to efficiently obtain sums over all lattice sites, since this sum can be factorized:","category":"page"},{"location":"","page":"Home","title":"Home","text":"allindices = [getindex.(Ref(i), 1:5) for i in CartesianIndices(Tuple(localdims))]\nsumorig = sum(f.(allindices))\nprintln(\"Sum of original function: $sumorig\")\n\nsumtt = sum(tci)\nprintln(\"Sum of tensor train: $sumtt\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"For further information, see sum.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This factorized sum can be used for efficient evaluation of high-dimensional integrals. This is implemented with Gauss-Kronrod quadrature rules in integrate. For example, the integral","category":"page"},{"location":"","page":"Home","title":"Home","text":"I = 10^3 intlimits_-1 +1^10 d^10 vecx \n     cosleft(10 textstylesum_n=1^10 x_n^2 right)\n     expleft-10^-3left(textstylesum_n=1^10 x_nright)^4right","category":"page"},{"location":"","page":"Home","title":"Home","text":"is evaluated by the following code:","category":"page"},{"location":"","page":"Home","title":"Home","text":"function f(x)\n    return 1e3 * cos(10 * sum(x .^ 2)) * exp(-sum(x)^4 / 1e3)\nend\nI = TCI.integrate(Float64, f, fill(-1.0, 10), fill(+1.0, 10); GKorder=15, tolerance=1e-8)\nprintln(\"GK15 integral value: $I\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"The argument GKorder controls the Gauss-Kronrod quadrature rule used for the integration, and tolerance controls the tolerance in the TCI approximation, which is distinct from the tolerance in the integral. For complicated functions, it is recommended to integrate using two different GK rules and to compare the results to get a good estimate of the discretization error.","category":"page"},{"location":"#Properties-of-the-TCI-object","page":"Home","title":"Properties of the TCI object","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"After running the code above, tci is a TensorCI2 object that can be interrogated for various properties. The most important ones are the rank (i.e. maximum bond dimension) and the link dimensions:","category":"page"},{"location":"","page":"Home","title":"Home","text":"println(\"Maximum bond dimension / rank of tci: $(TCI.rank(tci))\")\nprintln(\"Bond dimensions along the links of tci: $(TCI.linkdims(tci))\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"The latter can be plotted conveniently:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Plots, LaTeXStrings\nbondindices = 1:length(tci)-1\nplot(\n    bondindices,\n    min.(10 .^ bondindices, 10 .^ (length(tci) .- bondindices)),\n    yscale=:log10,\n    label=\"full rank\")\nplot!(bondindices, TCI.linkdims(tci), label=\"TCI compression\")\nxlabel!(L\"\\ell\")\nylabel!(L\"D_\\ell\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"Other methods are documented in the Tensor cross interpolation (TCI) section of the documentation.","category":"page"},{"location":"#Checking-convergence","page":"Home","title":"Checking convergence","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The vectors ranks and errors contain the pivot errors reached for different maximum bond dimensions. They are intended for convergence checks. The last element of errors can be used to check whether the tolerance was met within the maximum number of iterations:","category":"page"},{"location":"","page":"Home","title":"Home","text":"println(\"Error in last iteration was: $(last(errors))\")\nprintln(\"Is this below tolerance? $(last(errors) < tolerance)\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"Plotting errors against ranks shows convergence behavior. In most cases, convergence will become exponential after some initial iterations. Furthermore, tci.pivoterrors[D] contains the error that a truncation to bond dimension D would incur. Plotting both, we see tha","category":"page"},{"location":"","page":"Home","title":"Home","text":"plot(ranks, errors, yscale=:log10, seriestype=:scatter)\nplot!(tci.pivoterrors / tci.maxsamplevalue, yscale=:log10)\nylims!(1e-10, 2)\nxlabel!(L\"D_\\max\")\nylabel!(L\"\\varepsilon\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note that the errors are normalized with tci.maxsamplevalue, i.e. the maximum function value that was encountered during construction of the tci. This behaviour can be disabled by passing normalizeerror=false to crossinterpolate2.","category":"page"},{"location":"#Optimizing-the-first-pivot","page":"Home","title":"Optimizing the first pivot","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Sometimes, the performance of TCI is suboptimal due to an unfortunate choice of first pivot. In most cases, it is sufficient to choose a first pivot close to structure, e.g. on a maximum of the function. Simply pass the first pivot as a parameter to crossinterpolate2:","category":"page"},{"location":"","page":"Home","title":"Home","text":"firstpivot = [1, 2, 3, 4, 5]\ntci, ranks, errors = TCI.crossinterpolate2(\n    Float64, f, localdims, [firstpivot]; tolerance=tolerance\n)","category":"page"},{"location":"","page":"Home","title":"Home","text":"If this is not known (or you still have difficulties with bad convergence), the method optfirstpivot provides a simple algorithm to find a good first pivot.","category":"page"},{"location":"","page":"Home","title":"Home","text":"firstpivot = optfirstpivot(f, localdims, [1, 2, 3, 4, 5])\ntci, ranks, errors = TCI.crossinterpolate2(\n    Float64, f, localdims, [firstpivot]; tolerance=tolerance\n)","category":"page"},{"location":"","page":"Home","title":"Home","text":"This algorithm optimizes the given index set (in this case [1, 2, 3, 4, 5]) by searching for a maximum absolute value, alternating through the dimensions. If no starting point is given, [1, 1, ...] is used.","category":"page"},{"location":"#Combing-TCI2-and-global-pivot-search","page":"Home","title":"Combing TCI2 and global pivot search","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The main algorithm for adding new pivots in TCI2 is the 2-site algorithm, which is local. The 2-site algorithm alone may miss some regions with high interpolation error.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The current TCI2 implementation provides the combination of the 2-site algorithm and a global search algorithm to find such regions. This functionality is activated by default. In the function crossinterpolate2, we alternate between a 2-site-update sweep and a global pivot insertion. After a 2-site-update sweep, we search for index sets with high interpolation errors (> the given tolerance multiplied by the parameter tolmarginglobalsearch) and add them to the TCI2 object, and then we continue with a 2-site-update sweep.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The number of initial points used in one global search is controlled by the parameter nsearchglobalpivot. You may consider increasing this number if the global search is not effective (check the number of pivots found and timings of the global search by setting verbosity to a higher value!). The maximum number of global pivots inserted at once is controlled by the parameter maxnglobalpivot.","category":"page"},{"location":"","page":"Home","title":"Home","text":"A rare failure case is that the global search find the index sets with high interpolation errors, but the 2-site algorithm fails to add these pivots into the TCI2 object. This will end up adding the same index sets in the next global search, leading to an endless loop.","category":"page"},{"location":"#Estiamte-true-interpolation-error-by-random-global-search","page":"Home","title":"Estiamte true interpolation error by random global search","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Since most of the TCI update algorithms are local, the true interpolation error is not known. However, the error can be estimated by global searches. This is implemented in the function estimatetrueerror:","category":"page"},{"location":"","page":"Home","title":"Home","text":"pivoterrors = TCI.estimatetrueerror(TCI.TensorTrain(tci), f)","category":"page"},{"location":"","page":"Home","title":"Home","text":"This function approximately estimates the error that would be reached by repeating a greedy search from a random initial point. The result is a vector of a found indexset and the corresponding error, sorted by error. The error is the maximum absolute difference between the function and the TT approximation.","category":"page"},{"location":"#Caching","page":"Home","title":"Caching","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"During constructing a TCI, the function to be interpolated can be evaluated for the same index set multiple times. If an evaluation of the function to be interpolated is costly, i.e., takes more than 100 ns, it may be beneficial to cache the results of function evaluations. CachedFunction{T} provides this functionality.","category":"page"},{"location":"","page":"Home","title":"Home","text":"We can wrap your function as follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"import TensorCrossInterpolation as TCI\n\n# Local dimensions of TCI\nlocaldims = [2, 2, 2, 2]\n\n# Function to be interpolated. Evaluation take 2 seconds.\nf(x) = (sleep(2); sum(x))\n\n# Cached Function. `T` is the return type of the function.\ncf = TCI.CachedFunction{Float64}(f, localdims)\n\n# The first evaluation takes two seconds. The result will be cached.\nx = [1, 1, 1, 1]\n@time cf(x)\n\n# Cached value is returned (Really quick!).\n@time cf(x)","category":"page"},{"location":"#Batch-Evalaution","page":"Home","title":"Batch Evalaution","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"By default, in TCI2, the function to be interpolated is evaluated for a single index at a time. However, there may be a need to parallelize the code by evaluating the function across multiple index sets concurrently using several CPU cores. This type of custom optimization can be achieved through batch evaluation.","category":"page"},{"location":"","page":"Home","title":"Home","text":"To utilize this feature, your function must inherit from  TCI.BatchEvaluator{T} and supports two additional types of function calls for evaluating mathrmT (one local index) and Pi tensors (two local indices):","category":"page"},{"location":"","page":"Home","title":"Home","text":"import TensorCrossInterpolation as TCI\nimport TensorCrossInterpolation: MultiIndex\n\nstruct TestFunction{T} <: TCI.BatchEvaluator{T}\n    localdims::Vector{Int}\n    function TestFunction{T}(localdims) where {T}\n        new{T}(localdims)\n    end\nend\n\n# Evaluation for a single index set\nfunction (obj::TestFunction{T})(indexset::MultiIndex)::T where {T}\n    return sum(indexset)\nend\n\n\n# Evaluaiton of a T tensor with one local index\nfunction (obj::TestFunction{T})(leftindexset::Vector{MultiIndex}, rightindexset::Vector{MultiIndex}, ::Val{1})::Array{T,3} where {T}\n    if length(leftindexset) * length(rightindexset) == 0\n        return Array{T,3}(undef, 0, 0, 0, 0)\n    end\n\n    nl = length(leftindexset[1])\n    # This can be parallelized if you want\n    result = [obj(vcat(l, s1, r)) for l in leftindexset, s1 in 1:obj.localdims[nl+1], r in rightindexset]\n    return reshape(result, length(leftindexset), obj.localdims[nl+1], length(rightindexset))\nend\n\n\n# Evaluaiton of a Pi tensor with two local indices\nfunction (obj::TestFunction{T})(leftindexset::Vector{MultiIndex}, rightindexset::Vector{MultiIndex}, ::Val{2})::Array{T,4} where {T}\n    if length(leftindexset) * length(rightindexset) == 0\n        return Array{T,4}(undef, 0, 0, 0, 0)\n    end\n\n    nl = length(leftindexset[1])\n    # This can be parallelized if you want\n    result = [obj(vcat(l, s1, s2, r)) for l in leftindexset, s1 in 1:obj.localdims[nl+1], s2 in 1:obj.localdims[nl+2], r in rightindexset]\n    return reshape(result, length(leftindexset), obj.localdims[nl+1:nl+2]..., length(rightindexset))\nend\n\nlocaldims = [2, 2, 2, 2, 2]\nf = TestFunction{Float64}(localdims)\n\n# Compute T tensor\nlet\n    leftindexset = [[1, 1, 1], [2, 2, 1], [2, 1, 1]]\n    rightindexset = [[1, 1], [2, 2], [1, 2]]\n\n    # The returned object has shape of (3, 2, 3)\n    @assert f(leftindexset, rightindexset, Val(1)) ≈ [sum(vcat(l, s1, r)) for l in leftindexset, s1 in 1:localdims[4], r in rightindexset]\nend\n\n# Compute Pi tensor\nlet\n    leftindexset = [[1, 1], [2, 2], [2, 1]]\n    rightindexset = [[1, 1], [2, 2], [1, 2]]\n\n    # The returned object has shape of (3, 2, 2, 3)\n    @assert f(leftindexset, rightindexset, Val(2)) ≈ [sum(vcat(l, s1, s2, r)) for l in leftindexset, s1 in 1:localdims[3], s2 in 1:localdims[4], r in rightindexset]\nend","category":"page"},{"location":"","page":"Home","title":"Home","text":"CachedFunction{T}  can wrap a function inheriting from BatchEvaluator{T}. In such cases, CachedFunction{T}  caches the results of batch evaluation.","category":"page"},{"location":"#Batch-evaluation-parallelization","page":"Home","title":"Batch evaluation + parallelization","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The batch evalution can be combined with parallelization using threads, MPI, etc. The following sample code use Threads to parallelize function evaluations. Note that the function evaluation for a single index set must be thread-safe.","category":"page"},{"location":"","page":"Home","title":"Home","text":"We can run the code as (with 6 threads):","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia --project=@. -t 6 samplecode.jl","category":"page"},{"location":"","page":"Home","title":"Home","text":"import TensorCrossInterpolation as TCI\nimport TensorCrossInterpolation: MultiIndex\n\nstruct TestFunction{T} <: TCI.BatchEvaluator{T}\n    localdims::Vector{Int}\n    function TestFunction{T}(localdims) where {T}\n        new{T}(localdims)\n    end\nend\n\n# Evaluation for a single index set (takes 1 millisec)\nfunction (obj::TestFunction{T})(indexset::MultiIndex)::T where {T}\n    sleep(1e-3)\n    return sum(indexset)\nend\n\n\n# Batch evaluation (loop over all index sets)\nfunction (obj::TestFunction{T})(leftindexset::Vector{Vector{Int}}, rightindexset::Vector{Vector{Int}}, ::Val{M})::Array{T,M + 2} where {T,M}\n    if length(leftindexset) * length(rightindexset) == 0\n        return Array{T,M+2}(undef, ntuple(i->0, M+2)...)\n    end\n\n    nl = length(first(leftindexset))\n\n    t = time_ns()\n    cindexset = vec(collect(Iterators.product(ntuple(i->1:obj.localdims[nl+i], M)...)))\n    elements = collect(Iterators.product(1:length(leftindexset), 1:length(cindexset), 1:length(rightindexset)))\n    result = Array{T,3}(undef, length(leftindexset), length(cindexset), length(rightindexset))\n    t2 = time_ns()\n\n    Threads.@threads for indices in elements\n        l, c, r = leftindexset[indices[1]], cindexset[indices[2]], rightindexset[indices[3]]\n        result[indices...] = obj(vcat(l, c..., r))\n    end\n    t3 = time_ns()\n    println(\"Time: \", (t2-t)/1e9, \" \", (t3-t2)/1e9)\n    return reshape(result, length(leftindexset), obj.localdims[nl+1:nl+M]..., length(rightindexset))\nend\n\n\nL = 20\nlocaldims = fill(2, L)\nf = TestFunction{Float64}(localdims)\n\nprintln(\"Number of threads: \", Threads.nthreads())\n\n# Compute Pi tensor\nnl = 10\nnr = L - nl - 2\n\n# 20 left index sets, 20 right index sets\nleftindexset = [[rand(1:d) for d in localdims[1:nl]] for _ in 1:20]\nrightindexset = [[rand(1:d) for d in localdims[nl+3:end]] for _ in 1:20]\n\nf(leftindexset, rightindexset, Val(2))\n\nfor i in 1:4\n    @time f(leftindexset, rightindexset, Val(2))\nend","category":"page"},{"location":"","page":"Home","title":"Home","text":"If your function is thread-safe, you can parallelize your function readily using ThreadedBatchEvaluator as follows (the internal implementation is identical to the sample code shown above):","category":"page"},{"location":"","page":"Home","title":"Home","text":"import TensorCrossInterpolation as TCI\n\n# Evaluation takes 1 millisecond, make sure the function is thread-safe.\nfunction f(x)\n    sleep(1e-3)\n    return sum(x)\nend\n\n\nL = 20\nlocaldims = fill(2, L)\nparf = TCI.ThreadedBatchEvaluator{Float64}(f, localdims)\n\nprintln(\"Number of threads: \", Threads.nthreads())\n\n# Compute Pi tensor\nnl = 10\nnr = L - nl - 2\n\n# 20 left index sets, 20 right index sets\nleftindexset = [[rand(1:d) for d in localdims[1:nl]] for _ in 1:20]\nrightindexset = [[rand(1:d) for d in localdims[nl+3:end]] for _ in 1:20]\n\nparf(leftindexset, rightindexset, Val(2))\n\nfor i in 1:4\n    @time parf(leftindexset, rightindexset, Val(2))\nend","category":"page"},{"location":"","page":"Home","title":"Home","text":"You can simply pass the wrapped function parf to crossinterpolate2.","category":"page"},{"location":"documentation/#Documentation","page":"Documentation","title":"Documentation","text":"","category":"section"},{"location":"documentation/","page":"Documentation","title":"Documentation","text":"Documentation of all types and methods in module TensorCrossInterpolation.","category":"page"},{"location":"documentation/#Matrix-approximation","page":"Documentation","title":"Matrix approximation","text":"","category":"section"},{"location":"documentation/#Matrix-cross-interpolation-(MCI)","page":"Documentation","title":"Matrix cross interpolation (MCI)","text":"","category":"section"},{"location":"documentation/","page":"Documentation","title":"Documentation","text":"Modules = [TensorCrossInterpolation]\nPages = [\"matrixci.jl\"]","category":"page"},{"location":"documentation/#TensorCrossInterpolation.MatrixCI","page":"Documentation","title":"TensorCrossInterpolation.MatrixCI","text":"mutable struct MatrixCrossInterpolation{T}\n\nRepresents a cross interpolation of a matrix - or, to be more precise, the data necessary to evaluate a cross interpolation. This data can be fed into various methods such as evaluate(c, i, j) to get interpolated values, and be improved by dynamically adding pivots.\n\n\n\n\n\n","category":"type"},{"location":"documentation/#TensorCrossInterpolation.AinvtimesB-Tuple{AbstractMatrix, AbstractVecOrMat}","page":"Documentation","title":"TensorCrossInterpolation.AinvtimesB","text":"AtimesBinv(A::Matrix, B::Matrix)\n\nCalculates the matrix product A^-1 B, given a square matrix A and a rectangular matrix B in a numerically stable way using QR decomposition. This is useful in case A^-1 is ill-conditioned.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.AtimesBinv-Tuple{AbstractVecOrMat, AbstractMatrix}","page":"Documentation","title":"TensorCrossInterpolation.AtimesBinv","text":"AtimesBinv(A::Matrix, B::Matrix)\n\nCalculates the matrix product A B^-1, given a rectangular matrix A and a square matrix B in a numerically stable way using QR decomposition. This is useful in case B^-1 is ill-conditioned.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.addpivot!-Union{Tuple{T}, Tuple{TensorCrossInterpolation.MatrixCI{T}, AbstractMatrix{T}, Union{Pair{Int64, Int64}, Tuple{Int64, Int64}, CartesianIndex{2}}}} where T","page":"Documentation","title":"TensorCrossInterpolation.addpivot!","text":"function addpivot(\n    a::AbstractMatrix{T},\n    ci::MatrixCrossInterpolation{T},\n    pivotindices::AbstractArray{T, 2})\n\nAdd a new pivot given by pivotindices to the cross interpolation ci of the matrix a.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.addpivot!-Union{Tuple{T}, Tuple{TensorCrossInterpolation.MatrixCI{T}, AbstractMatrix{T}}} where T","page":"Documentation","title":"TensorCrossInterpolation.addpivot!","text":"function addpivot(\n    a::AbstractMatrix{T},\n    ci::MatrixCrossInterpolation{T})\n\nAdd a new pivot that maximizes the error to the cross interpolation ci of the matrix a.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.crossinterpolate-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T","page":"Documentation","title":"TensorCrossInterpolation.crossinterpolate","text":"function crossinterpolate(\n    a::AbstractMatrix{T};\n    tolerance=1e-6,\n    maxiter=200,\n    firstpivot=argmax(abs.(a))\n) where {T}\n\nCross interpolate a mtimes n matrix a, i.e. find a set of indices I and J, such that a(1ldots m 1ldots n) approx a(1ldots m I) (a(I J))^-1 a(J 1ldots m).\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.findnewpivot-Union{Tuple{T}, Tuple{TensorCrossInterpolation.AbstractMatrixCI{T}, AbstractMatrix{T}}, Tuple{TensorCrossInterpolation.AbstractMatrixCI{T}, AbstractMatrix{T}, Vector{Int64}}, Tuple{TensorCrossInterpolation.AbstractMatrixCI{T}, AbstractMatrix{T}, Vector{Int64}, Vector{Int64}}} where T","page":"Documentation","title":"TensorCrossInterpolation.findnewpivot","text":"findnewpivot(\n    a::AbstractMatrix{T},\n    ci::MatrixCrossInterpolation{T},\n    row_indices::Union{Vector{Int}},\n    col_indices::Union{Vector{Int}})\n\nFinds the pivot that maximizes the local error across all components of a and ci within the subset given by rowindices and colindices. By default, all avalable rows of ci will be considered.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.localerror-Union{Tuple{T}, Tuple{TensorCrossInterpolation.AbstractMatrixCI{T}, AbstractMatrix{T}}, Tuple{TensorCrossInterpolation.AbstractMatrixCI{T}, AbstractMatrix{T}, Union{Colon, Int64, AbstractVector{Int64}}}, Tuple{TensorCrossInterpolation.AbstractMatrixCI{T}, AbstractMatrix{T}, Union{Colon, Int64, AbstractVector{Int64}}, Union{Colon, Int64, AbstractVector{Int64}}}} where T","page":"Documentation","title":"TensorCrossInterpolation.localerror","text":"localerror(\n    a::AbstractMatrix{T},\n    ci::MatrixCrossInterpolation{T},\n    row_indices::Union{AbstractVector{Int},Colon,Int}=Colon(),\n    col_indices::Union{AbstractVector{Int},Colon,Int}=Colon())\n\nReturns all local errors of the cross interpolation ci with respect to matrix a. To find local errors on a submatrix, specify rowindices or colindices.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#Adaptive-cross-approximation-(ACA)","page":"Documentation","title":"Adaptive cross approximation (ACA)","text":"","category":"section"},{"location":"documentation/","page":"Documentation","title":"Documentation","text":"Modules = [TensorCrossInterpolation]\nPages = [\"matrixaca.jl\"]","category":"page"},{"location":"documentation/#TensorCrossInterpolation.addpivot!-Union{Tuple{T}, Tuple{TensorCrossInterpolation.MatrixACA{T}, AbstractMatrix{T}, Union{Pair{Int64, Int64}, Tuple{Int64, Int64}, CartesianIndex{2}}}} where T","page":"Documentation","title":"TensorCrossInterpolation.addpivot!","text":"function addpivot!(a::AbstractMatrix{T}, aca::MatrixACA{T})\n\nFind and add a new pivot according to the ACA algorithm in Kumar 2016 ()\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.uk-Union{Tuple{T}, Tuple{TensorCrossInterpolation.MatrixACA{T}, Any}} where T","page":"Documentation","title":"TensorCrossInterpolation.uk","text":"Compute u_k(x) for all x\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.vk-Union{Tuple{T}, Tuple{TensorCrossInterpolation.MatrixACA{T}, Any}} where T","page":"Documentation","title":"TensorCrossInterpolation.vk","text":"Compute v_k(y) for all y\n\n\n\n\n\n","category":"method"},{"location":"documentation/#Rank-revealing-LU-decomposition-(rrLU)","page":"Documentation","title":"Rank-revealing LU decomposition (rrLU)","text":"","category":"section"},{"location":"documentation/","page":"Documentation","title":"Documentation","text":"Modules = [TensorCrossInterpolation]\nPages = [\"matrixlu.jl\", \"matrixluci.jl\"]","category":"page"},{"location":"documentation/#Base.:\\-Union{Tuple{T}, Tuple{TensorCrossInterpolation.rrLU{T}, AbstractMatrix{T}}} where T","page":"Documentation","title":"Base.:\\","text":"Override solving Ax = b using LU decomposition\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.lastpivoterror-Union{Tuple{TensorCrossInterpolation.rrLU{T}}, Tuple{T}} where T","page":"Documentation","title":"TensorCrossInterpolation.lastpivoterror","text":"Correct estimate of the last pivot error A special care is taken for a full-rank matrix: the last pivot error is set to zero.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.rrlu!-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T","page":"Documentation","title":"TensorCrossInterpolation.rrlu!","text":"function rrlu!(\n    A::AbstractMatrix{T};\n    maxrank::Int=typemax(Int),\n    reltol::Number=1e-14,\n    abstol::Number=0.0,\n    leftorthogonal::Bool=true\n)::rrLU{T} where {T}\n\nRank-revealing LU decomposition.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.rrlu-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T","page":"Documentation","title":"TensorCrossInterpolation.rrlu","text":"function rrlu(\n    A::AbstractMatrix{T};\n    maxrank::Int=typemax(Int),\n    reltol::Number=1e-14,\n    abstol::Number=0.0,\n    leftorthogonal::Bool=true\n)::rrLU{T} where {T}\n\nRank-revealing LU decomposition.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.solve-Union{Tuple{T}, Tuple{Matrix{T}, Matrix{T}, Matrix{T}}} where T","page":"Documentation","title":"TensorCrossInterpolation.solve","text":"Solve (LU) x = b\n\nL: lower triangular matrix U: upper triangular matrix b: right-hand side vector\n\nReturn x\n\nNote: Not optimized for performance\n\n\n\n\n\n","category":"method"},{"location":"documentation/#Tensor-trains-and-tensor-cross-Interpolation","page":"Documentation","title":"Tensor trains and tensor cross Interpolation","text":"","category":"section"},{"location":"documentation/#Tensor-train-(TT)","page":"Documentation","title":"Tensor train (TT)","text":"","category":"section"},{"location":"documentation/","page":"Documentation","title":"Documentation","text":"Modules = [TensorCrossInterpolation]\nPages = [\"abstracttensortrain.jl\", \"tensortrain.jl\", \"contraction.jl\"]","category":"page"},{"location":"documentation/#TensorCrossInterpolation.AbstractTensorTrain","page":"Documentation","title":"TensorCrossInterpolation.AbstractTensorTrain","text":"abstract type AbstractTensorTrain{V} <: Function end\n\nAbstract type that is a supertype to all tensor train types found in this module. The main purpose of this type is for the definition of functions such as rank and linkdims that are shared between different tensor train classes.\n\nWhen iterated over, the tensor train will return each of the tensors in order.\n\nImplementations: TensorTrain, TensorCI2, TensorCI1\n\n\n\n\n\n","category":"type"},{"location":"documentation/#Base.:+-Union{Tuple{V}, Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}, TensorCrossInterpolation.AbstractTensorTrain{V}}} where V","page":"Documentation","title":"Base.:+","text":"function (+)(lhs::AbstractTensorTrain{V}, rhs::AbstractTensorTrain{V}) where {V}\n\nAddition of two tensor trains. If c = a + b, then c(v) ≈ a(v) + b(v) at each index set v. Note that this function increases the bond dimension, i.e. chi_textresult = chi_1 + chi_2 if the original tensor trains had bond dimensions chi_1 and chi_2. Can be combined with automatic recompression by calling add.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#Base.:--Union{Tuple{V}, Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}, TensorCrossInterpolation.AbstractTensorTrain{V}}} where V","page":"Documentation","title":"Base.:-","text":"function (-)(lhs::AbstractTensorTrain{V}, rhs::AbstractTensorTrain{V}) where {V}\n\nSubtraction of two tensor trains. If c = a - b, then c(v) ≈ a(v) - b(v) at each index set v. Note that this function increases the bond dimension, i.e. chi_textresult = chi_1 + chi_2 if the original tensor trains had bond dimensions chi_1 and chi_2. Can be combined with automatic recompression by calling subtract (see documentation for add).\n\n\n\n\n\n","category":"method"},{"location":"documentation/#Base.length-Union{Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}}, Tuple{V}} where V","page":"Documentation","title":"Base.length","text":"function length(tt::AbstractTensorTrain{V}) where {V}\n\nLength of the tensor train, i.e. the number of tensors in the tensor train.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#Base.sum-Union{Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}}, Tuple{V}} where V","page":"Documentation","title":"Base.sum","text":"function sum(tt::TensorTrain{V}) where {V}\n\nEvaluates the sum of the tensor train approximation over all lattice sites in an efficient factorized manner.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#LinearAlgebra.norm-Union{Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}}, Tuple{V}} where V","page":"Documentation","title":"LinearAlgebra.norm","text":"Frobenius norm of a tensor train.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#LinearAlgebra.norm2-Union{Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}}, Tuple{V}} where V","page":"Documentation","title":"LinearAlgebra.norm2","text":"Squared Frobenius norm of a tensor train.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#LinearAlgebra.rank-Union{Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}}, Tuple{V}} where V","page":"Documentation","title":"LinearAlgebra.rank","text":"function rank(tt::AbstractTensorTrain{V}) where {V}\n\nRank of the tensor train, i.e. the maximum link dimension.\n\nSee also: linkdims, linkdim\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.add-Union{Tuple{V}, Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}, TensorCrossInterpolation.AbstractTensorTrain{V}}} where V","page":"Documentation","title":"TensorCrossInterpolation.add","text":"function add(\n    lhs::AbstractTensorTrain{V}, rhs::AbstractTensorTrain{V};\n    factorlhs=one(V), factorrhs=one(V),\n    tolerance::Float64=0.0, maxbonddim::Int=typemax(Int)\n) where {V}\n\nAddition of two tensor trains. If C = add(A, B), then C(v) ≈ A(v) + B(v) at each index set v. Note that this function increases the bond dimension, i.e. chi_textresult = chi_1 + chi_2 if the original tensor trains had bond dimensions chi_1 and chi_2.\n\nArguments:\n\nlhs, rhs: Tensor trains to be added.\nfactorlhs, factorrhs: Factors to multiply each tensor train by before addition.\ntolerance, maxbonddim: Parameters to be used for the recompression step.\n\nReturns: A new TensorTrain representing the function factorlhs * lhs(v) + factorrhs * rhs(v).\n\nSee also: +\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.evaluate-Union{Tuple{V}, Tuple{N}, Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}, Union{NTuple{N, Int64}, AbstractVector{Int64}}}} where {N, V}","page":"Documentation","title":"TensorCrossInterpolation.evaluate","text":"function evaluate(\n    tt::TensorTrain{V},\n    indexset::Union{AbstractVector{LocalIndex}, NTuple{N, LocalIndex}}\n)::V where {N, V}\n\nEvaluates the tensor train tt at indices given by indexset.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.evaluate-Union{Tuple{V}, Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}, CartesianIndex}} where V","page":"Documentation","title":"TensorCrossInterpolation.evaluate","text":"function evaluate(tt::TensorTrain{V}, indexset::CartesianIndex) where {V}\n\nEvaluates the tensor train tt at indices given by indexset.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.linkdim-Union{Tuple{V}, Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}, Int64}} where V","page":"Documentation","title":"TensorCrossInterpolation.linkdim","text":"function linkdim(tt::AbstractTensorTrain{V}, i::Int)::Int where {V}\n\nBond dimensions at the link between tensor T_i and T_i+1 in the tensor train.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.linkdims-Union{Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}}, Tuple{V}} where V","page":"Documentation","title":"TensorCrossInterpolation.linkdims","text":"function linkdims(tt::AbstractTensorTrain{V})::Vector{Int} where {V}\n\nBond dimensions along the links between T tensors in the tensor train.\n\nSee also: rank\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.sitedim-Union{Tuple{V}, Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}, Int64}} where V","page":"Documentation","title":"TensorCrossInterpolation.sitedim","text":"function linkdim(tt::AbstractTensorTrain{V}, i::Int)::Int where {V}\n\nDimension of the ith site index along the tensor train.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.sitedims-Union{Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}}, Tuple{V}} where V","page":"Documentation","title":"TensorCrossInterpolation.sitedims","text":"function sitedims(tt::AbstractTensorTrain{V})::Vector{Vector{Int}} where {V}\n\nDimensions of the site indices (local indices, physical indices) of the tensor train.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.sitetensor-Union{Tuple{V}, Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}, Any}} where V","page":"Documentation","title":"TensorCrossInterpolation.sitetensor","text":"sitetensors(tt::AbstractTensorTrain{V}, i) where {V}\n\nThe tensor at site i of the tensor train.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.sitetensors-Union{Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}}, Tuple{V}} where V","page":"Documentation","title":"TensorCrossInterpolation.sitetensors","text":"sitetensors(tt::AbstractTensorTrain{V}) where {V}\n\nThe tensors that make up the tensor train.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.subtract-Union{Tuple{V}, Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}, TensorCrossInterpolation.AbstractTensorTrain{V}}} where V","page":"Documentation","title":"TensorCrossInterpolation.subtract","text":"function subtract(\n    lhs::AbstractTensorTrain{V}, rhs::AbstractTensorTrain{V};\n    tolerance::Float64=0.0, maxbonddim::Int=typemax(Int)\n)\n\nSubtract two tensor trains lhs and rhs. See add.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.TTCache","page":"Documentation","title":"TensorCrossInterpolation.TTCache","text":"struct TTCache{ValueType}\n\nCached evalulation of a tensor train. This is useful when the same TT is evaluated multiple times with the same indices. The number of site indices per tensor core can be arbitray irrespective of the number of site indices of the original tensor train.\n\n\n\n\n\n","category":"type"},{"location":"documentation/#TensorCrossInterpolation.TensorTrain","page":"Documentation","title":"TensorCrossInterpolation.TensorTrain","text":"struct TensorTrain{ValueType}\n\nRepresents a tensor train, also known as MPS.\n\nThe tensor train can be evaluated using standard function call notation:\n\n    tt = TensorTrain(...)\n    value = tt([1, 2, 3, 4])\n\nThe corresponding function is:\n\nfunction (tt::TensorTrain{V})(indexset) where {V}\n\nEvaluates the tensor train tt at indices given by indexset.\n\n\n\n\n\n","category":"type"},{"location":"documentation/#TensorCrossInterpolation.TensorTrain-Union{Tuple{AbstractVector{<:AbstractArray{V, N}}}, Tuple{N}, Tuple{V}} where {V, N}","page":"Documentation","title":"TensorCrossInterpolation.TensorTrain","text":"function TensorTrain(sitetensors::Vector{Array{V, 3}}) where {V}\n\nCreate a tensor train out of a vector of tensors. Each tensor should have links to the previous and next tensor as dimension 1 and 3, respectively; the local index (\"physical index\" for MPS in physics) is dimension 2.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.TensorTrain-Union{Tuple{N}, Tuple{V2}, Tuple{V}, Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}, Any}} where {V, V2, N}","page":"Documentation","title":"TensorCrossInterpolation.TensorTrain","text":"function TensorTrain{V2,N}(tci::AbstractTensorTrain{V}) where {V,V2,N}\n\nConvert a tensor-train-like object into a tensor train.\n\nArguments:\n\ntt::AbstractTensorTrain{V}: a tensor-train-like object.\nlocaldims: a vector of local dimensions for each tensor in the tensor train. A each element of localdims should be an array-like object of N-2 integers.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.TensorTrain-Union{Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}}, Tuple{V}} where V","page":"Documentation","title":"TensorCrossInterpolation.TensorTrain","text":"function TensorTrain(tci::AbstractTensorTrain{V}) where {V}\n\nConvert a tensor-train-like object into a tensor train. This includes TCI1 and TCI2 objects.\n\nSee also: TensorCI1, TensorCI2.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.TensorTrainFit","page":"Documentation","title":"TensorCrossInterpolation.TensorTrainFit","text":"Fitting data with a TensorTrain object. This may be useful when the interpolated function is noisy.\n\n\n\n\n\n","category":"type"},{"location":"documentation/#TensorCrossInterpolation.batchevaluate-Union{Tuple{M}, Tuple{V}, Tuple{TensorCrossInterpolation.TTCache{V}, AbstractVector{Vector{Int64}}, AbstractVector{Vector{Int64}}, Val{M}}, Tuple{TensorCrossInterpolation.TTCache{V}, AbstractVector{Vector{Int64}}, AbstractVector{Vector{Int64}}, Val{M}, Union{Nothing, AbstractVector{<:AbstractVector{<:Integer}}}}} where {V, M}","page":"Documentation","title":"TensorCrossInterpolation.batchevaluate","text":"projector: 0 means no projection, otherwise the index of the projector\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.compress!-Union{Tuple{TensorTrain{V, N}}, Tuple{N}, Tuple{V}, Tuple{TensorTrain{V, N}, Symbol}} where {V, N}","page":"Documentation","title":"TensorCrossInterpolation.compress!","text":"function compress!(\n    tt::TensorTrain{V, N},\n    method::Symbol=:LU;\n    tolerance::Float64=1e-12,\n    maxbonddim=typemax(Int)\n) where {V, N}\n\nCompress the tensor train tt using LU, CI or SVD decompositions.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.Contraction","page":"Documentation","title":"TensorCrossInterpolation.Contraction","text":"Contraction of two TTOs Optionally, the contraction can be done with a function applied to the result.\n\n\n\n\n\n","category":"type"},{"location":"documentation/#TensorCrossInterpolation.contract-Union{Tuple{V2}, Tuple{V1}, Tuple{TensorTrain{V1, 4}, TensorTrain{V2, 4}}} where {V1, V2}","page":"Documentation","title":"TensorCrossInterpolation.contract","text":"function contract(\n    A::TensorTrain{V1,4},\n    B::TensorTrain{V2,4};\n    algorithm::Symbol=:TCI,\n    tolerance::Float64=1e-12,\n    maxbonddim::Int=typemax(Int),\n    f::Union{Nothing,Function}=nothing,\n    kwargs...\n) where {V1,V2}\n\nContract two tensor trains A and B.\n\nCurrently, two implementations are available:\n\nalgorithm=:TCI constructs a new TCI that fits the contraction of A and B.\nalgorithm=:naive uses a naive tensor contraction and subsequent SVD recompression of the tensor train.\nalgorithm=:zipup uses a naive tensor contraction with on-the-fly LU decomposition.\n\nArguments:\n\nA and B are the tensor trains to be contracted.\nalgorithm chooses the algorithm used to evaluate the contraction.\ntolerance is the tolerance of the TCI or SVD recompression.\nmaxbonddim sets the maximum bond dimension of the resulting tensor train.\nf is a function to be applied elementwise to the result. This option is only available with algorithm=:TCI.\nmethod chooses the method used for the factorization in the algorithm=:zipup case (:SVD or :LU).\nkwargs... are forwarded to crossinterpolate2 if algorithm=:TCI.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.contract_zipup-Union{Tuple{ValueType}, Tuple{TensorTrain{ValueType, 4}, TensorTrain{ValueType, 4}}} where ValueType","page":"Documentation","title":"TensorCrossInterpolation.contract_zipup","text":"See SVD version: https://tensornetwork.org/mps/algorithms/zipupmpo/\n\n\n\n\n\n","category":"method"},{"location":"documentation/#Tensor-cross-interpolation-(TCI)","page":"Documentation","title":"Tensor cross interpolation (TCI)","text":"","category":"section"},{"location":"documentation/","page":"Documentation","title":"Documentation","text":"Note: In most cases, it is advantageous to use TensorCrossInterpolation.TensorCI2 instead.","category":"page"},{"location":"documentation/","page":"Documentation","title":"Documentation","text":"Modules = [TensorCrossInterpolation]\nPages = [\"tensorci1.jl\", \"indexset.jl\", \"sweepstrategies.jl\"]","category":"page"},{"location":"documentation/#TensorCrossInterpolation.TensorCI1","page":"Documentation","title":"TensorCrossInterpolation.TensorCI1","text":"mutable struct TensorCI1{ValueType} <: AbstractTensorTrain{ValueType}\n\nType that represents tensor cross interpolations created using the TCI1 algorithm. Users may want to create these using crossinterpolate1 rather than calling a constructor directly.\n\n\n\n\n\n","category":"type"},{"location":"documentation/#TensorCrossInterpolation.addpivot!-Union{Tuple{F}, Tuple{V}, Tuple{TensorCrossInterpolation.TensorCI1{V}, Int64, F}, Tuple{TensorCrossInterpolation.TensorCI1{V}, Int64, F, Float64}} where {V, F}","page":"Documentation","title":"TensorCrossInterpolation.addpivot!","text":"function addpivot!(tci::TensorCI1{V}, p::Int, tolerance::1e-12) where {V,F}\n\nAdd a pivot to the TCI at site p. Do not add a pivot if the error is below tolerance.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.addpivotcol!-Union{Tuple{V}, Tuple{TensorCrossInterpolation.TensorCI1{V}, TensorCrossInterpolation.MatrixCI{V}, Int64, Int64, Any}} where V","page":"Documentation","title":"TensorCrossInterpolation.addpivotcol!","text":"function addpivotcol!(tci::TensorCI1{V}, cross::MatrixCI{V}, p::Int, newj::Int, f) where {V}\n\nAdd the column with index newj as a pivot row to bond p.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.addpivotrow!-Union{Tuple{V}, Tuple{TensorCrossInterpolation.TensorCI1{V}, TensorCrossInterpolation.MatrixCI{V}, Int64, Int64, Any}} where V","page":"Documentation","title":"TensorCrossInterpolation.addpivotrow!","text":"function addpivotrow!(tci::TensorCI1{V}, cross::MatrixCI{V}, p::Int, newi::Int, f) where {V}\n\nAdd the row with index newi as a pivot row to bond p.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.crossinterpolate-Union{Tuple{N}, Tuple{ValueType}, Tuple{Type{ValueType}, Any, Union{NTuple{N, Int64}, Vector{Int64}}}, Tuple{Type{ValueType}, Any, Union{NTuple{N, Int64}, Vector{Int64}}, Vector{Int64}}} where {ValueType, N}","page":"Documentation","title":"TensorCrossInterpolation.crossinterpolate","text":"function crossinterpolate(\n    ::Type{ValueType},\n    f,\n    localdims::Union{Vector{Int},NTuple{N,Int}},\n    firstpivot::MultiIndex=ones(Int, length(localdims));\n    tolerance::Float64=1e-8,\n    maxiter::Int=200,\n    sweepstrategy::Symbol=:backandforth,\n    pivottolerance::Float64=1e-12,\n    verbosity::Int=0,\n    additionalpivots::Vector{MultiIndex}=MultiIndex[],\n    normalizeerror::Bool=true\n) where {ValueType, N}\n\nDeprecated, and only included for backward compatibility. Please use crossinterpolate1 instead.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.crossinterpolate1-Union{Tuple{N}, Tuple{ValueType}, Tuple{Type{ValueType}, Any, Union{NTuple{N, Int64}, Vector{Int64}}}, Tuple{Type{ValueType}, Any, Union{NTuple{N, Int64}, Vector{Int64}}, Vector{Int64}}} where {ValueType, N}","page":"Documentation","title":"TensorCrossInterpolation.crossinterpolate1","text":"function crossinterpolate1(\n    ::Type{ValueType},\n    f,\n    localdims::Union{Vector{Int},NTuple{N,Int}},\n    firstpivot::MultiIndex=ones(Int, length(localdims));\n    tolerance::Float64=1e-8,\n    maxiter::Int=200,\n    sweepstrategy::Symbol=:backandforth,\n    pivottolerance::Float64=1e-12,\n    verbosity::Int=0,\n    additionalpivots::Vector{MultiIndex}=MultiIndex[],\n    normalizeerror::Bool=true\n) where {ValueType, N}\n\nCross interpolate a function f(mathbfu), where mathbfu in 1 ldots d_1 times 1 ldots d_2 times ldots times 1 ldots d_mathscrL and d_1 ldots d_mathscrL are the local dimensions.\n\nArguments:\n\nValueType is the return type of f. Automatic inference is too error-prone.\nf is the function to be interpolated. f should have a single parameter, which is a vector of the same length as localdims. The return type should be ValueType.\nlocaldims::Union{Vector{Int},NTuple{N,Int}} is a Vector (or Tuple) that contains the local dimension of each index of f.\nfirstpivot::MultiIndex is the first pivot, used by the TCI algorithm for initialization. Default: [1, 1, ...].\ntolerance::Float64 is a float specifying the tolerance for the interpolation. Default: 1e-8.\nmaxiter::Int is the maximum number of iterations (i.e. optimization sweeps) before aborting the TCI construction. Default: 200.\nsweepstrategy::Symbol specifies whether to sweep forward (:forward), backward (:backward), or back and forth (:backandforth) during optimization. Default: :backandforth.\npivottolerance::Float64 specifies the tolerance below which no new pivot will be added to each tensor. Default: 1e-12.\nverbosity::Int can be set to >= 1 to get convergence information on standard output during optimization. Default: 0.\nadditionalpivots::Vector{MultiIndex} is a vector of additional pivots that the algorithm should add to the initial pivot before starting optimization. This is not necessary in most cases.\nnormalizeerror::Bool determines whether to scale the error by the maximum absolute value of f found during sampling. If set to false, the algorithm continues until the absolute error is below tolerance. If set to true, the algorithm uses the absolute error divided by the maximum sample instead. This is helpful if the magnitude of the function is not known in advance. Default: true.\n\nNotes:\n\nConvergence may depend on the choice of first pivot. A good rule of thumb is to choose firstpivot close to the largest structure in f, or on a maximum of f. If the structure of f is not known in advance, optfirstpivot may be helpful.\nBy default, no caching takes place. Use the CachedFunction wrapper if your function is expensive to evaluate.\n\nSee also: optfirstpivot, CachedFunction, crossinterpolate2\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.evaluate-Union{Tuple{V}, Tuple{N}, Tuple{TensorCrossInterpolation.TensorCI1{V}, Union{NTuple{N, Int64}, AbstractVector{Int64}}}} where {N, V}","page":"Documentation","title":"TensorCrossInterpolation.evaluate","text":"function evaluate(tci::TensorCI1{V}, indexset::AbstractVector{LocalIndex}) where {V}\n\nEvaluate the TCI at a specific set of indices. This method is inefficient; to evaluate many points, first convert the TCI object into a tensor train using tensortrain(tci).\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.getPi-Union{Tuple{F}, Tuple{V}, Tuple{TensorCrossInterpolation.TensorCI1{V}, Int64, F}} where {V, F}","page":"Documentation","title":"TensorCrossInterpolation.getPi","text":"buildPiAt(tci::TensorCrossInterpolation{V}, p::Int)\n\nBuild a 4-legged Pi tensor at site p. Indices are in the order i u_p u_p + 1 j, as in the TCI paper.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.isnested-Union{Tuple{T}, Tuple{Vector{T}, Vector{T}}, Tuple{Vector{T}, Vector{T}, Symbol}} where T","page":"Documentation","title":"TensorCrossInterpolation.isnested","text":"Return if a is nested in b (a  b). If row_or_col is :row/:col, the last/first element of each index in b is ignored, respectively.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#Tensor-cross-interpolation-2-(TCI2)","page":"Documentation","title":"Tensor cross interpolation 2 (TCI2)","text":"","category":"section"},{"location":"documentation/","page":"Documentation","title":"Documentation","text":"Modules = [TensorCrossInterpolation]\nPages = [\"tensorci2.jl\"]","category":"page"},{"location":"documentation/#TensorCrossInterpolation.TensorCI2","page":"Documentation","title":"TensorCrossInterpolation.TensorCI2","text":"mutable struct TensorCI2{ValueType} <: AbstractTensorTrain{ValueType}\n\nType that represents tensor cross interpolations created using the TCI2 algorithm. Users may want to create these using crossinterpolate2 rather than calling a constructor directly.\n\n\n\n\n\n","category":"type"},{"location":"documentation/#TensorCrossInterpolation.addglobalpivots!-Union{Tuple{ValueType}, Tuple{TensorCrossInterpolation.TensorCI2{ValueType}, Vector{Vector{Int64}}}} where ValueType","page":"Documentation","title":"TensorCrossInterpolation.addglobalpivots!","text":"Add global pivots to index sets\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.addglobalpivots1sitesweep!-Union{Tuple{ValueType}, Tuple{F}, Tuple{TensorCrossInterpolation.TensorCI2{ValueType}, F, Vector{Vector{Int64}}}} where {F, ValueType}","page":"Documentation","title":"TensorCrossInterpolation.addglobalpivots1sitesweep!","text":"Add global pivots to index sets and perform a 1site sweep\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.addglobalpivots2sitesweep!-Union{Tuple{ValueType}, Tuple{F}, Tuple{TensorCrossInterpolation.TensorCI2{ValueType}, F, Vector{Vector{Int64}}}} where {F, ValueType}","page":"Documentation","title":"TensorCrossInterpolation.addglobalpivots2sitesweep!","text":"Add global pivots to index sets and perform a 2site sweep. Retry until all pivots are added or until ntry iterations are reached.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.crossinterpolate2-Union{Tuple{N}, Tuple{ValueType}, Tuple{Type{ValueType}, Any, Union{NTuple{N, Int64}, Vector{Int64}}}, Tuple{Type{ValueType}, Any, Union{NTuple{N, Int64}, Vector{Int64}}, Vector{Vector{Int64}}}} where {ValueType, N}","page":"Documentation","title":"TensorCrossInterpolation.crossinterpolate2","text":"function crossinterpolate2(\n    ::Type{ValueType},\n    f,\n    localdims::Union{Vector{Int},NTuple{N,Int}},\n    initialpivots::Vector{MultiIndex}=[ones(Int, length(localdims))];\n    tolerance::Float64=1e-8,\n    pivottolerance::Float64=tolerance,\n    maxbonddim::Int=typemax(Int),\n    maxiter::Int=200,\n    sweepstrategy::Symbol=:backandforth,\n    pivotsearch::Symbol=:full,\n    verbosity::Int=0,\n    loginterval::Int=10,\n    normalizeerror::Bool=true,\n    ncheckhistory=3,\n    maxnglobalpivot::Int=5,\n    nsearchglobalpivot::Int=5,\n    tolmarginglobalsearch::Float64=10.0,\n    strictlynested::Bool=false\n) where {ValueType,N}\n\nCross interpolate a function f(mathbfu) using the TCI2 algorithm. Here, the domain of f is mathbfu in 1 ldots d_1 times 1 ldots d_2 times ldots times 1 ldots d_mathscrL and d_1 ldots d_mathscrL are the local dimensions.\n\nArguments:\n\nValueType is the return type of f. Automatic inference is too error-prone.\nf is the function to be interpolated. f should have a single parameter, which is a vector of the same length as localdims. The return type should be ValueType.\nlocaldims::Union{Vector{Int},NTuple{N,Int}} is a Vector (or Tuple) that contains the local dimension of each index of f.\ninitialpivots::Vector{MultiIndex} is a vector of pivots to be used for initialization. Default: [1, 1, ...].\ntolerance::Float64 is a float specifying the target tolerance for the interpolation. Default: 1e-8.\npivottolerance::Float64 is a float that specifies the tolerance for adding new pivots, i.e. the truncation of tensor train bonds. It should be <= tolerance, otherwise convergence may be impossible. Default: tolerance.\nmaxbonddim::Int specifies the maximum bond dimension for the TCI. Default: typemax(Int), i.e. effectively unlimited.\nmaxiter::Int is the maximum number of iterations (i.e. optimization sweeps) before aborting the TCI construction. Default: 200.\nsweepstrategy::Symbol specifies whether to sweep forward (:forward), backward (:backward), or back and forth (:backandforth) during optimization. Default: :backandforth.\npivotsearch::Symbol determins how pivots are searched (:full or :rook). Default: :full.\nverbosity::Int can be set to >= 1 to get convergence information on standard output during optimization. Default: 0.\nloginterval::Int can be set to >= 1 to specify how frequently to print convergence information. Default: 10.\nnormalizeerror::Bool determines whether to scale the error by the maximum absolute value of f found during sampling. If set to false, the algorithm continues until the absolute error is below tolerance. If set to true, the algorithm uses the absolute error divided by the maximum sample instead. This is helpful if the magnitude of the function is not known in advance. Default: true.\nncheckhistory::Int is the number of history points to use for convergence checks. Default: 3.\nmaxnglobalpivot::Int can be set to >= 0. Default: 5.\nnsearchglobalpivot::Int can be set to >= 0. Default: 5.\ntolmarginglobalsearch can be set to >= 1.0. Seach global pivots where the interpolation error is larger than the tolerance by tolmarginglobalsearch.  Default: 10.0.\nstrictlynested::Bool=false determines whether to preserve partial nesting in the TCI algorithm. Default: true.\ncheckbatchevaluatable::Bool Check if the function f is batch evaluatable. Default: false.\n\nNotes:\n\nSet tolerance to be > 0 or maxbonddim to some reasonable value. Otherwise, convergence is not reachable.\nBy default, no caching takes place. Use the CachedFunction wrapper if your function is expensive to evaluate.\n\nSee also: optimize!, optfirstpivot, CachedFunction, crossinterpolate1\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.invalidatesitetensors!-Union{Tuple{TensorCrossInterpolation.TensorCI2{T}}, Tuple{T}} where T","page":"Documentation","title":"TensorCrossInterpolation.invalidatesitetensors!","text":"Invalidate the site tensor at bond b.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.issitetensorsavailable-Union{Tuple{TensorCrossInterpolation.TensorCI2{T}}, Tuple{T}} where T","page":"Documentation","title":"TensorCrossInterpolation.issitetensorsavailable","text":"Return if site tensors are available\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.optimize!-Union{Tuple{ValueType}, Tuple{TensorCrossInterpolation.TensorCI2{ValueType}, Any}} where ValueType","page":"Documentation","title":"TensorCrossInterpolation.optimize!","text":"function optimize!(\n    tci::TensorCI2{ValueType},\n    f;\n    tolerance::Float64=1e-8,\n    maxbonddim::Int=typemax(Int),\n    maxiter::Int=200,\n    sweepstrategy::Symbol=:backandforth,\n    pivotsearch::Symbol=:full,\n    verbosity::Int=0,\n    loginterval::Int=10,\n    normalizeerror::Bool=true,\n    ncheckhistory=3,\n    maxnglobalpivot::Int=5,\n    nsearchglobalpivot::Int=5,\n    tolmarginglobalsearch::Float64=10.0,\n    strictlynested::Bool=false\n) where {ValueType}\n\nPerform optimization sweeps using the TCI2 algorithm. This will sucessively improve the TCI approximation of a function until it fits f with an error smaller than tolerance, or until the maximum bond dimension (maxbonddim) is reached.\n\nArguments:\n\ntci::TensorCI2{ValueType}: The TCI to optimize.\nf: The function to fit.\nf is the function to be interpolated. f should have a single parameter, which is a vector of the same length as localdims. The return type should be ValueType.\nlocaldims::Union{Vector{Int},NTuple{N,Int}} is a Vector (or Tuple) that contains the local dimension of each index of f.\ntolerance::Float64 is a float specifying the target tolerance for the interpolation. Default: 1e-8.\nmaxbonddim::Int specifies the maximum bond dimension for the TCI. Default: typemax(Int), i.e. effectively unlimited.\nmaxiter::Int is the maximum number of iterations (i.e. optimization sweeps) before aborting the TCI construction. Default: 200.\nsweepstrategy::Symbol specifies whether to sweep forward (:forward), backward (:backward), or back and forth (:backandforth) during optimization. Default: :backandforth.\npivotsearch::Symbol determins how pivots are searched (:full or :rook). Default: :full.\nverbosity::Int can be set to >= 1 to get convergence information on standard output during optimization. Default: 0.\nloginterval::Int can be set to >= 1 to specify how frequently to print convergence information. Default: 10.\nnormalizeerror::Bool determines whether to scale the error by the maximum absolute value of f found during sampling. If set to false, the algorithm continues until the absolute error is below tolerance. If set to true, the algorithm uses the absolute error divided by the maximum sample instead. This is helpful if the magnitude of the function is not known in advance. Default: true.\nncheckhistory::Int is the number of history points to use for convergence checks. Default: 3.\nmaxnglobalpivot::Int can be set to >= 0. Default: 5.\nnsearchglobalpivot::Int can be set to >= 0. Default: 5.\ntolmarginglobalsearch can be set to >= 1.0. Seach global pivots where the interpolation error is larger than the tolerance by tolmarginglobalsearch.  Default: 10.0.\nstrictlynested::Bool determines whether to preserve partial nesting in the TCI algorithm. Default: false.\ncheckbatchevaluatable::Bool Check if the function f is batch evaluatable. Default: false.\n\nNotes:\n\nSet tolerance to be > 0 or maxbonddim to some reasonable value. Otherwise, convergence is not reachable.\nBy default, no caching takes place. Use the CachedFunction wrapper if your function is expensive to evaluate.\n\nSee also: crossinterpolate2, optfirstpivot, CachedFunction, crossinterpolate1\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.printnestinginfo-Union{Tuple{TensorCrossInterpolation.TensorCI2{T}}, Tuple{T}} where T","page":"Documentation","title":"TensorCrossInterpolation.printnestinginfo","text":"function printnestinginfo(tci::TensorCI2{T}) where {T}\n\nPrint information about fulfillment of the nesting criterion (I_ell  I_ell+1 and J_ell  J_ell+1) on each pair of bonds ell ell+1 of tci to stdout.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.printnestinginfo-Union{Tuple{T}, Tuple{IO, TensorCrossInterpolation.TensorCI2{T}}} where T","page":"Documentation","title":"TensorCrossInterpolation.printnestinginfo","text":"function printnestinginfo(io::IO, tci::TensorCI2{T}) where {T}\n\nPrint information about fulfillment of the nesting criterion (I_ell  I_ell+1 and J_ell  J_ell+1) on each pair of bonds ell ell+1 of tci to io.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.searchglobalpivots-Union{Tuple{ValueType}, Tuple{TensorCrossInterpolation.TensorCI2{ValueType}, Any, Any}} where ValueType","page":"Documentation","title":"TensorCrossInterpolation.searchglobalpivots","text":"Search global pivots where the interpolation error exceeds abstol.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.sweep2site!-Union{Tuple{ValueType}, Tuple{TensorCrossInterpolation.TensorCI2{ValueType}, Any, Int64}} where ValueType","page":"Documentation","title":"TensorCrossInterpolation.sweep2site!","text":"Perform 2site sweeps on a TCI2.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.updatepivots!-Union{Tuple{ValueType}, Tuple{F}, Tuple{TensorCrossInterpolation.TensorCI2{ValueType}, Int64, F, Bool}} where {F, ValueType}","page":"Documentation","title":"TensorCrossInterpolation.updatepivots!","text":"Update pivots at bond b of tci using the TCI2 algorithm. Site tensors will be invalidated.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#Integration","page":"Documentation","title":"Integration","text":"","category":"section"},{"location":"documentation/","page":"Documentation","title":"Documentation","text":"Modules = [TensorCrossInterpolation]\nPages = [\"integration.jl\"]","category":"page"},{"location":"documentation/#TensorCrossInterpolation.integrate-Union{Tuple{ValueType}, Tuple{Type{ValueType}, Any, Vector{ValueType}, Vector{ValueType}}} where ValueType","page":"Documentation","title":"TensorCrossInterpolation.integrate","text":"function integrate(\n    ::Type{ValueType},\n    f,\n    a::Vector{ValueType},\n    b::Vector{ValueType};\n    tolerance=1e-8,\n    GKorder::Int=15\n) where {ValueType}\n\nIntegrate the function f using TCI and Gauss–Kronrod quadrature rules.\n\nArguments:\n\nValueType: return type off`.\na`: Vector of lower bounds in each dimension. Effectively, the lower corner of the hypercube that is being integrated over.\nb`: Vector of upper bounds in each dimension.\ntolerance: tolerance of the TCI approximation for the values of f.\nGKorder: Order of the Gauss–Kronrod rule, e.g. 15.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#Helpers-and-utility-methods","page":"Documentation","title":"Helpers and utility methods","text":"","category":"section"},{"location":"documentation/","page":"Documentation","title":"Documentation","text":"Modules = [TensorCrossInterpolation]\nPages = [\"cachedfunction.jl\", \"batcheval.jl\", \"util.jl\", \"globalsearch.jl\"]","category":"page"},{"location":"documentation/#TensorCrossInterpolation.CachedFunction","page":"Documentation","title":"TensorCrossInterpolation.CachedFunction","text":"Represents a function that maps ArgType -> ValueType and automatically caches function values. A CachedFunction object can be called in the same way as the original function using the usual function call syntax. The type K denotes the type of the keys used to cache function values, which could be an integer type. This defaults to UInt128. A safer but slower alternative is BigInt, which is better suited for functions with a large number of arguments. CachedFunction does not support batch evaluation of function values.\n\n\n\n\n\n","category":"type"},{"location":"documentation/#TensorCrossInterpolation.CachedFunction-Union{Tuple{K}, Tuple{ValueType}, Tuple{Function, Vector{Int64}}} where {ValueType, K}","page":"Documentation","title":"TensorCrossInterpolation.CachedFunction","text":"function CachedFunction{ValueType}(\n    f::Function,\n    localdims::Vector{Int}\n) where {ValueType}\n\nConstructor for a cached function that avoids repeated evaluation of the same values.\n\nArguments:\n\nValueType is the return type of f.\nK is the type for the keys used to cache function values. This defaults to UInt128.\nf is the function to be wrapped. It should take a vector of integers as its sole\n\nargument, and return a value of type ValueType.\n\nlocaldims is a Vector that describes the local dimensions of each argument of f.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.cachedata-Union{Tuple{TensorCrossInterpolation.CachedFunction{ValueType, K}}, Tuple{K}, Tuple{ValueType}} where {ValueType, K}","page":"Documentation","title":"TensorCrossInterpolation.cachedata","text":"Get all cached data of a CachedFunction object.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.BatchEvaluatorAdapter","page":"Documentation","title":"TensorCrossInterpolation.BatchEvaluatorAdapter","text":"Wrap any function to support batch evaluation.\n\n\n\n\n\n","category":"type"},{"location":"documentation/#TensorCrossInterpolation.ThreadedBatchEvaluator","page":"Documentation","title":"TensorCrossInterpolation.ThreadedBatchEvaluator","text":"ThreadedBatchEvaluator{T} is a wrapper for a function that supports batch evaluation parallelized over the index sets using threads. The function to be wrapped must be thread-safe.\n\n\n\n\n\n","category":"type"},{"location":"documentation/#TensorCrossInterpolation._batchevaluate_dispatch-Union{Tuple{M}, Tuple{V}, Tuple{Type{V}, Any, Vector{Int64}, AbstractVector{Vector{Int64}}, AbstractVector{Vector{Int64}}, Val{M}}} where {V, M}","page":"Documentation","title":"TensorCrossInterpolation._batchevaluate_dispatch","text":"This file contains functions for evaluating a function on a batch of indices mainly for TensorCI2. If the function supports batch evaluation, then it should implement the BatchEvaluator interface. Otherwise, the function is evaluated on each index individually using the usual function call syntax and loops.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation._batchevaluate_dispatch-Union{Tuple{M}, Tuple{V}, Tuple{Type{V}, TensorCrossInterpolation.BatchEvaluator{V}, Vector{Int64}, Vector{Vector{Int64}}, Vector{Vector{Int64}}, Val{M}}} where {V, M}","page":"Documentation","title":"TensorCrossInterpolation._batchevaluate_dispatch","text":"Calling batchevaluate on a function that supports batch evaluation will dispatch to this function.\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.optfirstpivot-Union{Tuple{N}, Tuple{Any, Union{NTuple{N, Int64}, Vector{Int64}}}, Tuple{Any, Union{NTuple{N, Int64}, Vector{Int64}}, Vector{Int64}}} where N","page":"Documentation","title":"TensorCrossInterpolation.optfirstpivot","text":"function optfirstpivot(\n    f,\n    localdims::Union{Vector{Int},NTuple{N,Int}},\n    firstpivot::MultiIndex=ones(Int, length(localdims));\n    maxsweep=1000\n) where {N}\n\nOptimize the first pivot for a tensor cross interpolation.\n\nArguments:\n\nf is function to be interpolated.\nlocaldims::Union{Vector{Int},NTuple{N,Int}} determines the local dimensions of the function parameters (see crossinterpolate1).\nfistpivot::MultiIndex=ones(Int, length(localdims)) is the starting point for the optimization. It is advantageous to choose it close to a global maximum of the function.\nmaxsweep is the maximum number of optimization sweeps. Default: 1000.\n\nSee also: crossinterpolate1\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.projector_to_slice-Tuple{AbstractVector{<:Integer}}","page":"Documentation","title":"TensorCrossInterpolation.projector_to_slice","text":"Construct slice for the site indces of one tensor core Returns a slice and the corresponding shape for resize\n\n\n\n\n\n","category":"method"},{"location":"documentation/#TensorCrossInterpolation.estimatetrueerror-Union{Tuple{ValueType}, Tuple{TensorTrain{ValueType, 3}, Any}} where ValueType","page":"Documentation","title":"TensorCrossInterpolation.estimatetrueerror","text":"function estimatetrueerror(\n    tt::TensorTrain{ValueType,3}, f;\n    nsearch::Int = 100,\n    initialpoints::Union{Nothing,AbstractVector{MultiIndex}} = nothing,\n)::Vector{Tuple{MultiIndex,Float64}} where {ValueType}\n\nEstimate the global error by comparing the exact function value and the TT approximation using a greedy algorithm and returns a unique list of pairs of the pivot and the error (error is the absolute difference between the exact function value and the TT approximation). On return, the list is sorted in descending order of the error.\n\nArguments:\n\ntt::TensorTrain{ValueType,3}: The tensor train to be compared with f\nf: The function to be compared with tt.\nnsearch::Int: The number of initial points to be used in the search (defaults to 100).\ninitialpoints::Union{Nothing,AbstractVector{MultiIndex}}: The initial points to be used in the search (defaults to nothing). If initialpoints is not nothing, nsearch is ignored.\n\n\n\n\n\n","category":"method"},{"location":"implementation/","page":"Implementation details","title":"Implementation details","text":"CurrentModule = TensorCrossInterpolation","category":"page"},{"location":"implementation/#Implementation","page":"Implementation details","title":"Implementation","text":"","category":"section"},{"location":"implementation/","page":"Implementation details","title":"Implementation details","text":"This document gives an overview to this implementation of the TCI algorithm. First, we will show how the high-level components work together to produce a TCI without going into detail; a detailed introduction of each component follows.","category":"page"},{"location":"implementation/#Overall-structure","page":"Implementation details","title":"Overall structure","text":"","category":"section"},{"location":"implementation/#[crossinterpolate](@ref)","page":"Implementation details","title":"crossinterpolate","text":"","category":"section"},{"location":"implementation/","page":"Implementation details","title":"Implementation details","text":"This function takes a target function to be approximated and constructs a TCI up to some specified tolerance using a sweeping algorithm. The steps are as follows:","category":"page"},{"location":"implementation/","page":"Implementation details","title":"Implementation details","text":"Initialize the TCI structure (TensorCI1) using f(firstpivot).\nIterate for iter = 1...maxiter\nIf iter is odd, sweep forward, else, sweep backward. During the sweep, add one pivot to each link using addpivot!.\nUpdate errornormalization to the maximum sample so far.\nIf max(pivoterrors) / errornormalization < tolerance, abort iteration.\nReturn the TCI.","category":"page"},{"location":"implementation/#Initialization","page":"Implementation details","title":"Initialization","text":"","category":"section"},{"location":"implementation/","page":"Implementation details","title":"Implementation details","text":"TODO.","category":"page"},{"location":"implementation/#Data-to-keep-track-of-/-Glossary-of-member-variables","page":"Implementation details","title":"Data to keep track of / Glossary of member variables","text":"","category":"section"},{"location":"implementation/","page":"Implementation details","title":"Implementation details","text":"TODO.","category":"page"},{"location":"implementation/#Sweeps","page":"Implementation details","title":"Sweeps","text":"","category":"section"},{"location":"implementation/","page":"Implementation details","title":"Implementation details","text":"Sweeps are done by applying addpivot! to each link ell = 1ldotsmathscrL in ascending order for forward sweeps and descending order for backward sweeps.","category":"page"},{"location":"implementation/#[addpivot!](@ref)","page":"Implementation details","title":"addpivot!","text":"","category":"section"},{"location":"implementation/","page":"Implementation details","title":"Implementation details","text":"This function adds one pivot at bond ell (in the code, we use p instead of ell). This is done as follows:","category":"page"},{"location":"implementation/","page":"Implementation details","title":"Implementation details","text":"If operatornamerank(ACA_ell) geq min(nrows(Pi_ell) ncols(Pi_ell)): Skip this bond and proceed with the next one, since we're already at full rank.\nEvaluate the error matrix E leftarrow lvert ACA_ell - Pi_ell rvert.\nNew pivot is at the maximum error (i j) leftarrow argmax E\nSave the last pivot error to pivoterrors_ell leftarrow Ei j\nIf Ei j  tau_textpivot (= 10^-16), skip this ell.\nOtherwise, add (i j) as a new pivot to this bond ell (see below).","category":"page"},{"location":"implementation/#Adding-a-pivot-(i,-j)-to-bond-\\ell","page":"Implementation details","title":"Adding a pivot (i j) to bond ell","text":"","category":"section"},{"location":"implementation/#[addpivotcol!](@ref)-and-[addpivotrow!](@ref)","page":"Implementation details","title":"addpivotcol! and addpivotrow!","text":"","category":"section"},{"location":"implementation/","page":"Implementation details","title":"Implementation details","text":"To add a pivot, we have to add a row and a column to T_ell P_ell and T_ell + 1. Afterwards, we update neighbouring Pi tensors Pi_ell-1 and Pi_ell+1 for efficiency.","category":"page"},{"location":"implementation/","page":"Implementation details","title":"Implementation details","text":"Construct an MCI (MatrixCI) object with row indices I, column indices J, columns C and rows R, where:\nRow indices MCII leftarrow Pi I_ell I_ell+1\nColumn indices MCIJ leftarrow Pi J_ell+1 J_ell\nColumn vectors MCIC leftarrow textreshape(T_ell D_ell-1times d_ell D_ell)\nRow vectors MCIR leftarrow textreshape(T_ell+1 D_ell d_ell+1 times D_ell+1)\nAdd the column j to the bond, like this:\nadd j to ACA_ell\nadd j to MCI\npush Pi J_ell+1j to J_ell\nSplit the legs of T_ell leftarrow textreshape(MCICD_ell-1 d_ell D_ell)\nUpdate P_ell leftarrow MCIP, where MCIP is obtained implicitly as a submatrix of MCIC.\nUpdate columns of Pi_ell-1\nAdd the row i to the bond, like this:\nadd i to ACA_ell\nadd i to MCI\npush Pi I_elli to I_ell+1\nUpdate T_ell+1 leftarrow textreshape(MCIR D_ell d_ell+1 D_ell+1)\nUpdate P_ell leftarrow MCIP\nUpdate rows of Pi_ell+1.","category":"page"}]
}

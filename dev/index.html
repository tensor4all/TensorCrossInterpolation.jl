<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · TensorCrossInterpolation.jl</title><meta name="title" content="Home · TensorCrossInterpolation.jl"/><meta property="og:title" content="Home · TensorCrossInterpolation.jl"/><meta property="twitter:title" content="Home · TensorCrossInterpolation.jl"/><meta name="description" content="Documentation for TensorCrossInterpolation.jl."/><meta property="og:description" content="Documentation for TensorCrossInterpolation.jl."/><meta property="twitter:description" content="Documentation for TensorCrossInterpolation.jl."/><meta property="og:url" content="https://github.com/tensor4all/TensorCrossInterpolation.jl/"/><meta property="twitter:url" content="https://github.com/tensor4all/TensorCrossInterpolation.jl/"/><link rel="canonical" href="https://github.com/tensor4all/TensorCrossInterpolation.jl/"/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>TensorCrossInterpolation.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Interpolating-functions"><span>Interpolating functions</span></a></li><li><a class="tocitem" href="#Sums-and-Integrals"><span>Sums and Integrals</span></a></li><li><a class="tocitem" href="#Properties-of-the-TCI-object"><span>Properties of the TCI object</span></a></li><li><a class="tocitem" href="#Checking-convergence"><span>Checking convergence</span></a></li><li><a class="tocitem" href="#Optimizing-the-first-pivot"><span>Optimizing the first pivot</span></a></li><li><a class="tocitem" href="#Combing-TCI2-and-global-pivot-search"><span>Combing TCI2 and global pivot search</span></a></li><li><a class="tocitem" href="#Estiamte-true-interpolation-error-by-random-global-search"><span>Estiamte true interpolation error by random global search</span></a></li><li><a class="tocitem" href="#Caching"><span>Caching</span></a></li><li><a class="tocitem" href="#Batch-Evalaution"><span>Batch Evalaution</span></a></li><li class="toplevel"><a class="tocitem" href="#Batch-evaluation-parallelization"><span>Batch evaluation + parallelization</span></a></li></ul></li><li><a class="tocitem" href="documentation/">Documentation</a></li><li><a class="tocitem" href="implementation/">Implementation details</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/tensor4all/TensorCrossInterpolation.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/tensor4all/TensorCrossInterpolation.jl/blob/main/docs/src/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="TensorCrossInterpolation"><a class="docs-heading-anchor" href="#TensorCrossInterpolation">TensorCrossInterpolation</a><a id="TensorCrossInterpolation-1"></a><a class="docs-heading-anchor-permalink" href="#TensorCrossInterpolation" title="Permalink"></a></h1><p>This is the documentation for <a href="https://github.com/tensor4all/TensorCrossInterpolation.jl">TensorCrossInterpolation</a>.</p><p>With the user manual and usage examples below, users should be able to use this library as a &quot;black box&quot; in most cases. Detailed documentation of (almost) all methods can be found in the <a href="documentation/#Documentation">Documentation</a> section, and <a href="implementation/#Implementation">Implementation</a> contains a detailed explanation of this implementation of TCI.</p><h2 id="Interpolating-functions"><a class="docs-heading-anchor" href="#Interpolating-functions">Interpolating functions</a><a id="Interpolating-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Interpolating-functions" title="Permalink"></a></h2><p>The most convenient way to create a TCI is <a href="documentation/#TensorCrossInterpolation.crossinterpolate2-Union{Tuple{N}, Tuple{ValueType}, Tuple{Type{ValueType}, Any, Union{Tuple{Vararg{Int64, N}}, Vector{Int64}}}, Tuple{Type{ValueType}, Any, Union{Tuple{Vararg{Int64, N}}, Vector{Int64}}, Vector{Vector{Int64}}}} where {ValueType, N}"><code>crossinterpolate2</code></a>. For example, consider the lorentzian in 5 dimensions, i.e. <span>$f(\mathbf v) = 1/(1 + \mathbf v^2)$</span> on a mesh <span>$\mathbf{v} \in \{1, 2, ..., 10\}^5$</span>. <span>$f$</span> can be interpolated as follows:</p><pre><code class="language-julia hljs">import TensorCrossInterpolation as TCI
f(v) = 1/(1 + v&#39; * v)
localdims = fill(10, 5)    # There are 5 tensor indices, each with values 1...10
tolerance = 1e-8
tci, ranks, errors = TCI.crossinterpolate2(Float64, f, localdims; tolerance=tolerance)
println(tci)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">TensorCrossInterpolation.TensorCI2{Float64} with rank 11</code></pre><p>Note that the return type of <code>f</code> has to be stated explicitly; inferring it automatically is too error-prone.</p><p>To evaluate the TCI approximation, simply call it the same way as the original function. For example, to evaluate it at <span>$(1, 2, 3, 4, 5)^T$</span>, use:</p><pre><code class="language-julia hljs">println(&quot;Original function: $(f([1, 2, 3, 4, 5]))&quot;)
println(&quot;TCI approximation: $(tci([1, 2, 3, 4, 5]))&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Original function: 0.017857142857142856
TCI approximation: 0.017857142857142853</code></pre><p>For easy integration into tensor network algorithms, the tensor train can be converted to ITensors MPS format. If you&#39;re using julia version 1.9 or later, an extension is automatically loaded if both <code>TensorCrossInterpolation.jl</code> and <code>ITensors.jl</code> are present. For older versions of julia, use the package using <a href="https://github.com/tensor4all/tciitensorconversion.jl">TCIITensorConversion.jl</a>.</p><h2 id="Sums-and-Integrals"><a class="docs-heading-anchor" href="#Sums-and-Integrals">Sums and Integrals</a><a id="Sums-and-Integrals-1"></a><a class="docs-heading-anchor-permalink" href="#Sums-and-Integrals" title="Permalink"></a></h2><p>Tensor trains are a way to efficiently obtain sums over all lattice sites, since this sum can be factorized:</p><pre><code class="language-julia hljs">allindices = [getindex.(Ref(i), 1:5) for i in CartesianIndices(Tuple(localdims))]
sumorig = sum(f.(allindices))
println(&quot;Sum of original function: $sumorig&quot;)

sumtt = sum(tci)
println(&quot;Sum of tensor train: $sumtt&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Sum of original function: 629.0966857809619
Sum of tensor train: 629.0966829751853</code></pre><p>For further information, see <a href="documentation/#Base.sum-Union{Tuple{TensorCrossInterpolation.AbstractTensorTrain{V}}, Tuple{V}} where V"><code>sum</code></a>.</p><p>This factorized sum can be used for efficient evaluation of high-dimensional integrals. This is implemented with Gauss-Kronrod quadrature rules in <a href="documentation/#TensorCrossInterpolation.integrate-Union{Tuple{ValueType}, Tuple{Type{ValueType}, Any, Vector{ValueType}, Vector{ValueType}}} where ValueType"><code>integrate</code></a>. For example, the integral</p><p class="math-container">\[I = 10^3 \int\limits_{[-1, +1]^{10}} d^{10} \vec{x} \,
     \cos\!\left(10 \textstyle\sum_{n=1}^{10} x_n^2 \right)
     \exp\!\left[-10^{-3}\left(\textstyle\sum_{n=1}^{10} x_n\right)^4\right]\]</p><p>is evaluated by the following code:</p><pre><code class="language-julia hljs">function f(x)
    return 1e3 * cos(10 * sum(x .^ 2)) * exp(-sum(x)^4 / 1e3)
end
I = TCI.integrate(Float64, f, fill(-1.0, 10), fill(+1.0, 10); GKorder=15, tolerance=1e-8)
println(&quot;GK15 integral value: $I&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">GK15 integral value: -5.496232627515932</code></pre><p>The argument <code>GKorder</code> controls the Gauss-Kronrod quadrature rule used for the integration, and <code>tolerance</code> controls the tolerance in the TCI approximation, which is distinct from the tolerance in the integral. For complicated functions, it is recommended to integrate using two different GK rules and to compare the results to get a good estimate of the discretization error.</p><h2 id="Properties-of-the-TCI-object"><a class="docs-heading-anchor" href="#Properties-of-the-TCI-object">Properties of the TCI object</a><a id="Properties-of-the-TCI-object-1"></a><a class="docs-heading-anchor-permalink" href="#Properties-of-the-TCI-object" title="Permalink"></a></h2><p>After running the code above, <code>tci</code> is a <a href="documentation/#TensorCrossInterpolation.TensorCI2"><code>TensorCI2</code></a> object that can be interrogated for various properties. The most important ones are the rank (i.e. maximum bond dimension) and the link dimensions:</p><pre><code class="language-julia hljs">println(&quot;Maximum bond dimension / rank of tci: $(TCI.rank(tci))&quot;)
println(&quot;Bond dimensions along the links of tci: $(TCI.linkdims(tci))&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Maximum bond dimension / rank of tci: 11
Bond dimensions along the links of tci: [10, 11, 11, 10]</code></pre><p>The latter can be plotted conveniently:</p><pre><code class="language-julia hljs">using Plots, LaTeXStrings
bondindices = 1:length(tci)-1
plot(
    bondindices,
    min.(10 .^ bondindices, 10 .^ (length(tci) .- bondindices)),
    yscale=:log10,
    label=&quot;full rank&quot;)
plot!(bondindices, TCI.linkdims(tci), label=&quot;TCI compression&quot;)
xlabel!(L&quot;\ell&quot;)
ylabel!(L&quot;D_\ell&quot;)</code></pre><img src="index-696cd993.svg" alt="Example block output"/><p>Other methods are documented in the <a href="documentation/#Tensor-cross-interpolation-(TCI)">Tensor cross interpolation (TCI)</a> section of the documentation.</p><h2 id="Checking-convergence"><a class="docs-heading-anchor" href="#Checking-convergence">Checking convergence</a><a id="Checking-convergence-1"></a><a class="docs-heading-anchor-permalink" href="#Checking-convergence" title="Permalink"></a></h2><p>The vectors <code>ranks</code> and <code>errors</code> contain the pivot errors reached for different maximum bond dimensions. They are intended for convergence checks. The last element of <code>errors</code> can be used to check whether the tolerance was met within the maximum number of iterations:</p><pre><code class="language-julia hljs">println(&quot;Error in last iteration was: $(last(errors))&quot;)
println(&quot;Is this below tolerance? $(last(errors) &lt; tolerance)&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Error in last iteration was: 1.9111313748018586e-9
Is this below tolerance? true</code></pre><p>Plotting <code>errors</code> against <code>ranks</code> shows convergence behavior. In most cases, convergence will become exponential after some initial iterations. Furthermore, <code>tci.pivoterrors[D]</code> contains the error that a truncation to bond dimension <code>D</code> would incur. Plotting both, we see tha</p><pre><code class="language-julia hljs">plot(ranks, errors, yscale=:log10, seriestype=:scatter)
plot!(tci.pivoterrors / tci.maxsamplevalue, yscale=:log10)
ylims!(1e-10, 2)
xlabel!(L&quot;D_\max&quot;)
ylabel!(L&quot;\varepsilon&quot;)</code></pre><img src="index-e01ef4ce.svg" alt="Example block output"/><p>Note that the errors are normalized with <code>tci.maxsamplevalue</code>, i.e. the maximum function value that was encountered during construction of the tci. This behaviour can be disabled by passing <code>normalizeerror=false</code> to <a href="documentation/#TensorCrossInterpolation.crossinterpolate2-Union{Tuple{N}, Tuple{ValueType}, Tuple{Type{ValueType}, Any, Union{Tuple{Vararg{Int64, N}}, Vector{Int64}}}, Tuple{Type{ValueType}, Any, Union{Tuple{Vararg{Int64, N}}, Vector{Int64}}, Vector{Vector{Int64}}}} where {ValueType, N}"><code>crossinterpolate2</code></a>.</p><h2 id="Optimizing-the-first-pivot"><a class="docs-heading-anchor" href="#Optimizing-the-first-pivot">Optimizing the first pivot</a><a id="Optimizing-the-first-pivot-1"></a><a class="docs-heading-anchor-permalink" href="#Optimizing-the-first-pivot" title="Permalink"></a></h2><p>Sometimes, the performance of TCI is suboptimal due to an unfortunate choice of first pivot. In most cases, it is sufficient to choose a first pivot close to structure, e.g. on a maximum of the function. Simply pass the first pivot as a parameter to <a href="documentation/#TensorCrossInterpolation.crossinterpolate2-Union{Tuple{N}, Tuple{ValueType}, Tuple{Type{ValueType}, Any, Union{Tuple{Vararg{Int64, N}}, Vector{Int64}}}, Tuple{Type{ValueType}, Any, Union{Tuple{Vararg{Int64, N}}, Vector{Int64}}, Vector{Vector{Int64}}}} where {ValueType, N}"><code>crossinterpolate2</code></a>:</p><pre><code class="language-julia hljs">firstpivot = [1, 2, 3, 4, 5]
tci, ranks, errors = TCI.crossinterpolate2(
    Float64, f, localdims, [firstpivot]; tolerance=tolerance
)</code></pre><p>If this is not known (or you still have difficulties with bad convergence), the method <a href="documentation/#TensorCrossInterpolation.optfirstpivot-Union{Tuple{N}, Tuple{Any, Union{Tuple{Vararg{Int64, N}}, Vector{Int64}}}, Tuple{Any, Union{Tuple{Vararg{Int64, N}}, Vector{Int64}}, Vector{Int64}}} where N"><code>optfirstpivot</code></a> provides a simple algorithm to find a good first pivot.</p><pre><code class="language-julia hljs">firstpivot = optfirstpivot(f, localdims, [1, 2, 3, 4, 5])
tci, ranks, errors = TCI.crossinterpolate2(
    Float64, f, localdims, [firstpivot]; tolerance=tolerance
)</code></pre><p>This algorithm optimizes the given index set (in this case <code>[1, 2, 3, 4, 5]</code>) by searching for a maximum absolute value, alternating through the dimensions. If no starting point is given, <code>[1, 1, ...]</code> is used.</p><h2 id="Combing-TCI2-and-global-pivot-search"><a class="docs-heading-anchor" href="#Combing-TCI2-and-global-pivot-search">Combing TCI2 and global pivot search</a><a id="Combing-TCI2-and-global-pivot-search-1"></a><a class="docs-heading-anchor-permalink" href="#Combing-TCI2-and-global-pivot-search" title="Permalink"></a></h2><p>The main algorithm for adding new pivots in TCI2 is the 2-site algorithm, which is local. The 2-site algorithm alone may miss some regions with high interpolation error.</p><p>The current TCI2 implementation provides the combination of the 2-site algorithm and a global search algorithm to find such regions. This functionality is activated by default. In the function <a href="documentation/#TensorCrossInterpolation.crossinterpolate2-Union{Tuple{N}, Tuple{ValueType}, Tuple{Type{ValueType}, Any, Union{Tuple{Vararg{Int64, N}}, Vector{Int64}}}, Tuple{Type{ValueType}, Any, Union{Tuple{Vararg{Int64, N}}, Vector{Int64}}, Vector{Vector{Int64}}}} where {ValueType, N}"><code>crossinterpolate2</code></a>, we alternate between a 2-site-update sweep and a global pivot insertion. After a 2-site-update sweep, we search for index sets with high interpolation errors (&gt; the given tolerance multiplied by the parameter <code>tolmarginglobalsearch</code>) and add them to the TCI2 object, and then we continue with a 2-site-update sweep.</p><p>The number of initial points used in one global search is controlled by the parameter <code>nsearchglobalpivot</code>. You may consider increasing this number if the global search is not effective (check the number of pivots found and timings of the global search by setting <code>verbosity</code> to a higher value!). The maximum number of global pivots inserted at once is controlled by the parameter <code>maxnglobalpivot</code>.</p><p>A rare failure case is that the global search find the index sets with high interpolation errors, but the 2-site algorithm fails to add these pivots into the TCI2 object. This will end up adding the same index sets in the next global search, leading to an endless loop.</p><h2 id="Estiamte-true-interpolation-error-by-random-global-search"><a class="docs-heading-anchor" href="#Estiamte-true-interpolation-error-by-random-global-search">Estiamte true interpolation error by random global search</a><a id="Estiamte-true-interpolation-error-by-random-global-search-1"></a><a class="docs-heading-anchor-permalink" href="#Estiamte-true-interpolation-error-by-random-global-search" title="Permalink"></a></h2><p>Since most of the TCI update algorithms are local, the true interpolation error is not known. However, the error can be estimated by global searches. This is implemented in the function <a href="documentation/#TensorCrossInterpolation.estimatetrueerror-Union{Tuple{ValueType}, Tuple{TensorTrain{ValueType, 3}, Any}} where ValueType"><code>estimatetrueerror</code></a>:</p><pre><code class="language-julia hljs">pivoterrors = TCI.estimatetrueerror(TCI.TensorTrain(tci), f)</code></pre><p>This function approximately estimates the error that would be reached by repeating a greedy search from a random initial point. The result is a vector of a found indexset and the corresponding error, sorted by error. The error is the maximum absolute difference between the function and the TT approximation.</p><h2 id="Caching"><a class="docs-heading-anchor" href="#Caching">Caching</a><a id="Caching-1"></a><a class="docs-heading-anchor-permalink" href="#Caching" title="Permalink"></a></h2><p>During constructing a TCI, the function to be interpolated can be evaluated for the same index set multiple times. If an evaluation of the function to be interpolated is costly, i.e., takes more than 100 ns, it may be beneficial to cache the results of function evaluations. <code>CachedFunction{T}</code> provides this functionality.</p><p>We can wrap your function as follows:</p><pre><code class="language-Julia hljs">import TensorCrossInterpolation as TCI

# Local dimensions of TCI
localdims = [2, 2, 2, 2]

# Function to be interpolated. Evaluation take 2 seconds.
f(x) = (sleep(2); sum(x))

# Cached Function. `T` is the return type of the function.
cf = TCI.CachedFunction{Float64}(f, localdims)

# The first evaluation takes two seconds. The result will be cached.
x = [1, 1, 1, 1]
@time cf(x)

# Cached value is returned (Really quick!).
@time cf(x)</code></pre><h2 id="Batch-Evalaution"><a class="docs-heading-anchor" href="#Batch-Evalaution">Batch Evalaution</a><a id="Batch-Evalaution-1"></a><a class="docs-heading-anchor-permalink" href="#Batch-Evalaution" title="Permalink"></a></h2><p>By default, in TCI2, the function to be interpolated is evaluated for a single index at a time. However, there may be a need to parallelize the code by evaluating the function across multiple index sets concurrently using several CPU cores. This type of custom optimization can be achieved through batch evaluation.</p><p>To utilize this feature, your function must inherit from  <code>TCI.BatchEvaluator{T}</code> and supports two additional types of function calls for evaluating <span>$\mathrm{T}$</span> (one local index) and <span>$\Pi$</span> tensors (two local indices):</p><pre><code class="language-julia hljs">import TensorCrossInterpolation as TCI
import TensorCrossInterpolation: MultiIndex

struct TestFunction{T} &lt;: TCI.BatchEvaluator{T}
    localdims::Vector{Int}
    function TestFunction{T}(localdims) where {T}
        new{T}(localdims)
    end
end

# Evaluation for a single index set
function (obj::TestFunction{T})(indexset::MultiIndex)::T where {T}
    return sum(indexset)
end


# Evaluaiton of a T tensor with one local index
function (obj::TestFunction{T})(leftindexset::Vector{MultiIndex}, rightindexset::Vector{MultiIndex}, ::Val{1})::Array{T,3} where {T}
    if length(leftindexset) * length(rightindexset) == 0
        return Array{T,3}(undef, 0, 0, 0, 0)
    end

    nl = length(leftindexset[1])
    # This can be parallelized if you want
    result = [obj(vcat(l, s1, r)) for l in leftindexset, s1 in 1:obj.localdims[nl+1], r in rightindexset]
    return reshape(result, length(leftindexset), obj.localdims[nl+1], length(rightindexset))
end


# Evaluaiton of a Pi tensor with two local indices
function (obj::TestFunction{T})(leftindexset::Vector{MultiIndex}, rightindexset::Vector{MultiIndex}, ::Val{2})::Array{T,4} where {T}
    if length(leftindexset) * length(rightindexset) == 0
        return Array{T,4}(undef, 0, 0, 0, 0)
    end

    nl = length(leftindexset[1])
    # This can be parallelized if you want
    result = [obj(vcat(l, s1, s2, r)) for l in leftindexset, s1 in 1:obj.localdims[nl+1], s2 in 1:obj.localdims[nl+2], r in rightindexset]
    return reshape(result, length(leftindexset), obj.localdims[nl+1:nl+2]..., length(rightindexset))
end

localdims = [2, 2, 2, 2, 2]
f = TestFunction{Float64}(localdims)

# Compute T tensor
let
    leftindexset = [[1, 1, 1], [2, 2, 1], [2, 1, 1]]
    rightindexset = [[1, 1], [2, 2], [1, 2]]

    # The returned object has shape of (3, 2, 3)
    @assert f(leftindexset, rightindexset, Val(1)) ≈ [sum(vcat(l, s1, r)) for l in leftindexset, s1 in 1:localdims[4], r in rightindexset]
end

# Compute Pi tensor
let
    leftindexset = [[1, 1], [2, 2], [2, 1]]
    rightindexset = [[1, 1], [2, 2], [1, 2]]

    # The returned object has shape of (3, 2, 2, 3)
    @assert f(leftindexset, rightindexset, Val(2)) ≈ [sum(vcat(l, s1, s2, r)) for l in leftindexset, s1 in 1:localdims[3], s2 in 1:localdims[4], r in rightindexset]
end</code></pre><p><code>CachedFunction{T}</code>  can wrap a function inheriting from <code>BatchEvaluator{T}</code>. In such cases, <code>CachedFunction{T}</code>  caches the results of batch evaluation.</p><h1 id="Batch-evaluation-parallelization"><a class="docs-heading-anchor" href="#Batch-evaluation-parallelization">Batch evaluation + parallelization</a><a id="Batch-evaluation-parallelization-1"></a><a class="docs-heading-anchor-permalink" href="#Batch-evaluation-parallelization" title="Permalink"></a></h1><p>The batch evalution can be combined with parallelization using threads, MPI, etc. The following sample code use <code>Threads</code> to parallelize function evaluations. Note that the function evaluation for a single index set must be thread-safe.</p><p>We can run the code as (with 6 threads):</p><pre><code class="language-Bash hljs">julia --project=@. -t 6 samplecode.jl</code></pre><pre><code class="language-Julia hljs">import TensorCrossInterpolation as TCI
import TensorCrossInterpolation: MultiIndex

struct TestFunction{T} &lt;: TCI.BatchEvaluator{T}
    localdims::Vector{Int}
    function TestFunction{T}(localdims) where {T}
        new{T}(localdims)
    end
end

# Evaluation for a single index set (takes 1 millisec)
function (obj::TestFunction{T})(indexset::MultiIndex)::T where {T}
    sleep(1e-3)
    return sum(indexset)
end


# Batch evaluation (loop over all index sets)
function (obj::TestFunction{T})(leftindexset::Vector{Vector{Int}}, rightindexset::Vector{Vector{Int}}, ::Val{M})::Array{T,M + 2} where {T,M}
    if length(leftindexset) * length(rightindexset) == 0
        return Array{T,M+2}(undef, ntuple(i-&gt;0, M+2)...)
    end

    nl = length(first(leftindexset))

    t = time_ns()
    cindexset = vec(collect(Iterators.product(ntuple(i-&gt;1:obj.localdims[nl+i], M)...)))
    elements = collect(Iterators.product(1:length(leftindexset), 1:length(cindexset), 1:length(rightindexset)))
    result = Array{T,3}(undef, length(leftindexset), length(cindexset), length(rightindexset))
    t2 = time_ns()

    Threads.@threads for indices in elements
        l, c, r = leftindexset[indices[1]], cindexset[indices[2]], rightindexset[indices[3]]
        result[indices...] = obj(vcat(l, c..., r))
    end
    t3 = time_ns()
    println(&quot;Time: &quot;, (t2-t)/1e9, &quot; &quot;, (t3-t2)/1e9)
    return reshape(result, length(leftindexset), obj.localdims[nl+1:nl+M]..., length(rightindexset))
end


L = 20
localdims = fill(2, L)
f = TestFunction{Float64}(localdims)

println(&quot;Number of threads: &quot;, Threads.nthreads())

# Compute Pi tensor
nl = 10
nr = L - nl - 2

# 20 left index sets, 20 right index sets
leftindexset = [[rand(1:d) for d in localdims[1:nl]] for _ in 1:20]
rightindexset = [[rand(1:d) for d in localdims[nl+3:end]] for _ in 1:20]

f(leftindexset, rightindexset, Val(2))

for i in 1:4
    @time f(leftindexset, rightindexset, Val(2))
end</code></pre><p>If your function is thread-safe, you can parallelize your function readily using <code>ThreadedBatchEvaluator</code> as follows (the internal implementation is identical to the sample code shown above):</p><pre><code class="language-Julia hljs">import TensorCrossInterpolation as TCI

# Evaluation takes 1 millisecond, make sure the function is thread-safe.
function f(x)
    sleep(1e-3)
    return sum(x)
end


L = 20
localdims = fill(2, L)
parf = TCI.ThreadedBatchEvaluator{Float64}(f, localdims)

println(&quot;Number of threads: &quot;, Threads.nthreads())

# Compute Pi tensor
nl = 10
nr = L - nl - 2

# 20 left index sets, 20 right index sets
leftindexset = [[rand(1:d) for d in localdims[1:nl]] for _ in 1:20]
rightindexset = [[rand(1:d) for d in localdims[nl+3:end]] for _ in 1:20]

parf(leftindexset, rightindexset, Val(2))

for i in 1:4
    @time parf(leftindexset, rightindexset, Val(2))
end</code></pre><p>You can simply pass the wrapped function <code>parf</code> to <code>crossinterpolate2</code>.</p></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="documentation/">Documentation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.5.0 on <span class="colophon-date" title="Wednesday 3 July 2024 09:40">Wednesday 3 July 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
